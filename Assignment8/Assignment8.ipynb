{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import datetime\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_val_predict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Accuracy means how close our full set of guesses are to being correct. If our guesses are primarily correct, that means we have a high accuracy.\n",
    "# Precision does not necessitate that our guesses are correct, but that they're closely clustered. High-precision guesses may have low accuracy, but be closely-packed, giving high precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The difference between precision and recall is item relevancy when faced with selecting instances from a larger set.\n",
    "# Precision measures how many of the selected instances are relevant, whereas Recall measures how many relevant instances are selected, compared to the full set of relevant instances available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius1</th>\n",
       "      <th>Texture1</th>\n",
       "      <th>Perimeter1</th>\n",
       "      <th>Area1</th>\n",
       "      <th>Smoothness1</th>\n",
       "      <th>Compactness1</th>\n",
       "      <th>Concavity1</th>\n",
       "      <th>Concave Points1</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius3</th>\n",
       "      <th>Texture3</th>\n",
       "      <th>Perimeter3</th>\n",
       "      <th>Area3</th>\n",
       "      <th>Smoothness3</th>\n",
       "      <th>Compactness3</th>\n",
       "      <th>Concavity3</th>\n",
       "      <th>Concave Points3</th>\n",
       "      <th>Symmetry3</th>\n",
       "      <th>Fractal Dimension3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Diagnosis  Radius1  Texture1  Perimeter1   Area1  Smoothness1  \\\n",
       "0    842302         M    17.99     10.38      122.80  1001.0      0.11840   \n",
       "1    842517         M    20.57     17.77      132.90  1326.0      0.08474   \n",
       "2  84300903         M    19.69     21.25      130.00  1203.0      0.10960   \n",
       "3  84348301         M    11.42     20.38       77.58   386.1      0.14250   \n",
       "4  84358402         M    20.29     14.34      135.10  1297.0      0.10030   \n",
       "5    843786         M    12.45     15.70       82.57   477.1      0.12780   \n",
       "6    844359         M    18.25     19.98      119.60  1040.0      0.09463   \n",
       "7  84458202         M    13.71     20.83       90.20   577.9      0.11890   \n",
       "8    844981         M    13.00     21.82       87.50   519.8      0.12730   \n",
       "9  84501001         M    12.46     24.04       83.97   475.9      0.11860   \n",
       "\n",
       "   Compactness1  Concavity1  Concave Points1         ...          Radius3  \\\n",
       "0       0.27760     0.30010          0.14710         ...            25.38   \n",
       "1       0.07864     0.08690          0.07017         ...            24.99   \n",
       "2       0.15990     0.19740          0.12790         ...            23.57   \n",
       "3       0.28390     0.24140          0.10520         ...            14.91   \n",
       "4       0.13280     0.19800          0.10430         ...            22.54   \n",
       "5       0.17000     0.15780          0.08089         ...            15.47   \n",
       "6       0.10900     0.11270          0.07400         ...            22.88   \n",
       "7       0.16450     0.09366          0.05985         ...            17.06   \n",
       "8       0.19320     0.18590          0.09353         ...            15.49   \n",
       "9       0.23960     0.22730          0.08543         ...            15.09   \n",
       "\n",
       "   Texture3  Perimeter3   Area3  Smoothness3  Compactness3  Concavity3  \\\n",
       "0     17.33      184.60  2019.0       0.1622        0.6656      0.7119   \n",
       "1     23.41      158.80  1956.0       0.1238        0.1866      0.2416   \n",
       "2     25.53      152.50  1709.0       0.1444        0.4245      0.4504   \n",
       "3     26.50       98.87   567.7       0.2098        0.8663      0.6869   \n",
       "4     16.67      152.20  1575.0       0.1374        0.2050      0.4000   \n",
       "5     23.75      103.40   741.6       0.1791        0.5249      0.5355   \n",
       "6     27.66      153.20  1606.0       0.1442        0.2576      0.3784   \n",
       "7     28.14      110.60   897.0       0.1654        0.3682      0.2678   \n",
       "8     30.73      106.20   739.3       0.1703        0.5401      0.5390   \n",
       "9     40.68       97.65   711.4       0.1853        1.0580      1.1050   \n",
       "\n",
       "   Concave Points3  Symmetry3  Fractal Dimension3  \n",
       "0           0.2654     0.4601             0.11890  \n",
       "1           0.1860     0.2750             0.08902  \n",
       "2           0.2430     0.3613             0.08758  \n",
       "3           0.2575     0.6638             0.17300  \n",
       "4           0.1625     0.2364             0.07678  \n",
       "5           0.1741     0.3985             0.12440  \n",
       "6           0.1932     0.3063             0.08368  \n",
       "7           0.1556     0.3196             0.11510  \n",
       "8           0.2060     0.4378             0.10720  \n",
       "9           0.2210     0.4366             0.20750  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cancer.csv', sep=',')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.50      0.27      0.35        11\n",
      "  Malignant       0.84      0.93      0.89        46\n",
      "\n",
      "avg / total       0.78      0.81      0.78        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.92      0.94      0.93        35\n",
      "  Malignant       0.90      0.86      0.88        22\n",
      "\n",
      "avg / total       0.91      0.91      0.91        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.87      0.94      0.91        36\n",
      "  Malignant       0.89      0.76      0.82        21\n",
      "\n",
      "avg / total       0.88      0.88      0.87        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.93      0.90      0.91        29\n",
      "  Malignant       0.90      0.93      0.91        28\n",
      "\n",
      "avg / total       0.91      0.91      0.91        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.90      0.93      0.92        29\n",
      "  Malignant       0.93      0.89      0.91        28\n",
      "\n",
      "avg / total       0.91      0.91      0.91        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.96      1.00      0.98        45\n",
      "  Malignant       1.00      0.83      0.91        12\n",
      "\n",
      "avg / total       0.97      0.96      0.96        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.91      0.95      0.93        41\n",
      "  Malignant       0.86      0.75      0.80        16\n",
      "\n",
      "avg / total       0.89      0.89      0.89        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.95      0.95      0.95        44\n",
      "  Malignant       0.85      0.85      0.85        13\n",
      "\n",
      "avg / total       0.93      0.93      0.93        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.91      0.95      0.93        44\n",
      "  Malignant       0.82      0.69      0.75        13\n",
      "\n",
      "avg / total       0.89      0.89      0.89        57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.98      0.98      0.98        43\n",
      "  Malignant       0.92      0.92      0.92        13\n",
      "\n",
      "avg / total       0.96      0.96      0.96        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression()\n",
    "\n",
    "descriptors = ['Perimeter1','Area1','Compactness1','Concavity1','Texture1','Symmetry1']\n",
    "\n",
    "X = df[descriptors].values.reshape(-1,len(descriptors))\n",
    "Y = df['Diagnosis']\n",
    "\n",
    "folds = KFold(n_splits=10)\n",
    "\n",
    "accuracies = []\n",
    "    \n",
    "print()\n",
    "\n",
    "for train_idx, test_idx in folds.split(X, Y):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "\n",
    "    logreg.fit(X_train, Y_train)\n",
    "\n",
    "    pred = cross_val_predict(logreg,X_test,Y_test, cv=10)\n",
    "\n",
    "    accuracy = metrics.classification_report(Y_test, pred, target_names=[\"Benign\",\"Malignant\"])\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    print(accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With one exception, our overall scores hover around 90% accuracy, meaning the testing data both accurately predicts malignancy, and does so nearly unanimously for the most part.\n",
    "# Also, the support numbers show us that the size of the sample is not an accurate determinator of F1-score, as malignancy accuracy varies quite heavily in the two last reports, despite the same number of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Gender</th>\n",
       "      <th>FSIQ</th>\n",
       "      <th>VIQ</th>\n",
       "      <th>PIQ</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>MRI_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>133</td>\n",
       "      <td>132</td>\n",
       "      <td>124</td>\n",
       "      <td>118</td>\n",
       "      <td>64.5</td>\n",
       "      <td>816932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>140</td>\n",
       "      <td>150</td>\n",
       "      <td>124</td>\n",
       "      <td>.</td>\n",
       "      <td>72.5</td>\n",
       "      <td>1001121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>139</td>\n",
       "      <td>123</td>\n",
       "      <td>150</td>\n",
       "      <td>143</td>\n",
       "      <td>73.3</td>\n",
       "      <td>1038437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>133</td>\n",
       "      <td>129</td>\n",
       "      <td>128</td>\n",
       "      <td>172</td>\n",
       "      <td>68.8</td>\n",
       "      <td>965353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>137</td>\n",
       "      <td>132</td>\n",
       "      <td>134</td>\n",
       "      <td>147</td>\n",
       "      <td>65.0</td>\n",
       "      <td>951545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Female</td>\n",
       "      <td>99</td>\n",
       "      <td>90</td>\n",
       "      <td>110</td>\n",
       "      <td>146</td>\n",
       "      <td>69.0</td>\n",
       "      <td>928799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Female</td>\n",
       "      <td>138</td>\n",
       "      <td>136</td>\n",
       "      <td>131</td>\n",
       "      <td>138</td>\n",
       "      <td>64.5</td>\n",
       "      <td>991305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Female</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>98</td>\n",
       "      <td>175</td>\n",
       "      <td>66.0</td>\n",
       "      <td>854258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Male</td>\n",
       "      <td>89</td>\n",
       "      <td>93</td>\n",
       "      <td>84</td>\n",
       "      <td>134</td>\n",
       "      <td>66.3</td>\n",
       "      <td>904858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Male</td>\n",
       "      <td>133</td>\n",
       "      <td>114</td>\n",
       "      <td>147</td>\n",
       "      <td>172</td>\n",
       "      <td>68.8</td>\n",
       "      <td>955466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>132</td>\n",
       "      <td>129</td>\n",
       "      <td>124</td>\n",
       "      <td>118</td>\n",
       "      <td>64.5</td>\n",
       "      <td>833868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Male</td>\n",
       "      <td>141</td>\n",
       "      <td>150</td>\n",
       "      <td>128</td>\n",
       "      <td>151</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1079549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Male</td>\n",
       "      <td>135</td>\n",
       "      <td>129</td>\n",
       "      <td>124</td>\n",
       "      <td>155</td>\n",
       "      <td>69.0</td>\n",
       "      <td>924059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Female</td>\n",
       "      <td>140</td>\n",
       "      <td>120</td>\n",
       "      <td>147</td>\n",
       "      <td>155</td>\n",
       "      <td>70.5</td>\n",
       "      <td>856472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Female</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>146</td>\n",
       "      <td>66.0</td>\n",
       "      <td>878897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Female</td>\n",
       "      <td>83</td>\n",
       "      <td>71</td>\n",
       "      <td>96</td>\n",
       "      <td>135</td>\n",
       "      <td>68.0</td>\n",
       "      <td>865363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Female</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>120</td>\n",
       "      <td>127</td>\n",
       "      <td>68.5</td>\n",
       "      <td>852244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "      <td>102</td>\n",
       "      <td>178</td>\n",
       "      <td>73.5</td>\n",
       "      <td>945088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Female</td>\n",
       "      <td>101</td>\n",
       "      <td>112</td>\n",
       "      <td>84</td>\n",
       "      <td>136</td>\n",
       "      <td>66.3</td>\n",
       "      <td>808020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>180</td>\n",
       "      <td>70.0</td>\n",
       "      <td>889083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Male</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>892420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>97</td>\n",
       "      <td>107</td>\n",
       "      <td>84</td>\n",
       "      <td>186</td>\n",
       "      <td>76.5</td>\n",
       "      <td>905940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Female</td>\n",
       "      <td>135</td>\n",
       "      <td>129</td>\n",
       "      <td>134</td>\n",
       "      <td>122</td>\n",
       "      <td>62.0</td>\n",
       "      <td>790619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>139</td>\n",
       "      <td>145</td>\n",
       "      <td>128</td>\n",
       "      <td>132</td>\n",
       "      <td>68.0</td>\n",
       "      <td>955003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Female</td>\n",
       "      <td>91</td>\n",
       "      <td>86</td>\n",
       "      <td>102</td>\n",
       "      <td>114</td>\n",
       "      <td>63.0</td>\n",
       "      <td>831772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>141</td>\n",
       "      <td>145</td>\n",
       "      <td>131</td>\n",
       "      <td>171</td>\n",
       "      <td>72.0</td>\n",
       "      <td>935494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Female</td>\n",
       "      <td>85</td>\n",
       "      <td>90</td>\n",
       "      <td>84</td>\n",
       "      <td>140</td>\n",
       "      <td>68.0</td>\n",
       "      <td>798612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Male</td>\n",
       "      <td>103</td>\n",
       "      <td>96</td>\n",
       "      <td>110</td>\n",
       "      <td>187</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1062462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Female</td>\n",
       "      <td>77</td>\n",
       "      <td>83</td>\n",
       "      <td>72</td>\n",
       "      <td>106</td>\n",
       "      <td>63.0</td>\n",
       "      <td>793549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>130</td>\n",
       "      <td>126</td>\n",
       "      <td>124</td>\n",
       "      <td>159</td>\n",
       "      <td>66.5</td>\n",
       "      <td>866662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Female</td>\n",
       "      <td>133</td>\n",
       "      <td>126</td>\n",
       "      <td>132</td>\n",
       "      <td>127</td>\n",
       "      <td>62.5</td>\n",
       "      <td>857782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>144</td>\n",
       "      <td>145</td>\n",
       "      <td>137</td>\n",
       "      <td>191</td>\n",
       "      <td>67.0</td>\n",
       "      <td>949589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Male</td>\n",
       "      <td>103</td>\n",
       "      <td>96</td>\n",
       "      <td>110</td>\n",
       "      <td>192</td>\n",
       "      <td>75.5</td>\n",
       "      <td>997925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>Male</td>\n",
       "      <td>90</td>\n",
       "      <td>96</td>\n",
       "      <td>86</td>\n",
       "      <td>181</td>\n",
       "      <td>69.0</td>\n",
       "      <td>879987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "      <td>81</td>\n",
       "      <td>143</td>\n",
       "      <td>66.5</td>\n",
       "      <td>834344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>Female</td>\n",
       "      <td>133</td>\n",
       "      <td>129</td>\n",
       "      <td>128</td>\n",
       "      <td>153</td>\n",
       "      <td>66.5</td>\n",
       "      <td>948066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>140</td>\n",
       "      <td>150</td>\n",
       "      <td>124</td>\n",
       "      <td>144</td>\n",
       "      <td>70.5</td>\n",
       "      <td>949395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>94</td>\n",
       "      <td>139</td>\n",
       "      <td>64.5</td>\n",
       "      <td>893983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>Male</td>\n",
       "      <td>81</td>\n",
       "      <td>90</td>\n",
       "      <td>74</td>\n",
       "      <td>148</td>\n",
       "      <td>74.0</td>\n",
       "      <td>930016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>89</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>179</td>\n",
       "      <td>75.5</td>\n",
       "      <td>935863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Gender  FSIQ  VIQ  PIQ Weight Height  MRI_Count\n",
       "0            1  Female   133  132  124    118   64.5     816932\n",
       "1            2    Male   140  150  124      .   72.5    1001121\n",
       "2            3    Male   139  123  150    143   73.3    1038437\n",
       "3            4    Male   133  129  128    172   68.8     965353\n",
       "4            5  Female   137  132  134    147   65.0     951545\n",
       "5            6  Female    99   90  110    146   69.0     928799\n",
       "6            7  Female   138  136  131    138   64.5     991305\n",
       "7            8  Female    92   90   98    175   66.0     854258\n",
       "8            9    Male    89   93   84    134   66.3     904858\n",
       "9           10    Male   133  114  147    172   68.8     955466\n",
       "10          11  Female   132  129  124    118   64.5     833868\n",
       "11          12    Male   141  150  128    151   70.0    1079549\n",
       "12          13    Male   135  129  124    155   69.0     924059\n",
       "13          14  Female   140  120  147    155   70.5     856472\n",
       "14          15  Female    96  100   90    146   66.0     878897\n",
       "15          16  Female    83   71   96    135   68.0     865363\n",
       "16          17  Female   132  132  120    127   68.5     852244\n",
       "17          18    Male   100   96  102    178   73.5     945088\n",
       "18          19  Female   101  112   84    136   66.3     808020\n",
       "19          20    Male    80   77   86    180   70.0     889083\n",
       "20          21    Male    83   83   86      .      .     892420\n",
       "21          22    Male    97  107   84    186   76.5     905940\n",
       "22          23  Female   135  129  134    122   62.0     790619\n",
       "23          24    Male   139  145  128    132   68.0     955003\n",
       "24          25  Female    91   86  102    114   63.0     831772\n",
       "25          26    Male   141  145  131    171   72.0     935494\n",
       "26          27  Female    85   90   84    140   68.0     798612\n",
       "27          28    Male   103   96  110    187   77.0    1062462\n",
       "28          29  Female    77   83   72    106   63.0     793549\n",
       "29          30  Female   130  126  124    159   66.5     866662\n",
       "30          31  Female   133  126  132    127   62.5     857782\n",
       "31          32    Male   144  145  137    191   67.0     949589\n",
       "32          33    Male   103   96  110    192   75.5     997925\n",
       "33          34    Male    90   96   86    181   69.0     879987\n",
       "34          35  Female    83   90   81    143   66.5     834344\n",
       "35          36  Female   133  129  128    153   66.5     948066\n",
       "36          37    Male   140  150  124    144   70.5     949395\n",
       "37          38  Female    88   86   94    139   64.5     893983\n",
       "38          39    Male    81   90   74    148   74.0     930016\n",
       "39          40    Male    89   91   89    179   75.5     935863"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2\n",
    "\n",
    "brain_df = pd.read_csv('brain_size.csv', delimiter=';')\n",
    "\n",
    "brain_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
